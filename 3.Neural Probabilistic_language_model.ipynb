{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "chars = sorted(list(set(\"\".join(words))))\n",
    "stoi  = {s:i+1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos  = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape for input: torch.Size([32, 3]) ===> Targe shape torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# creating sample inputs and preds from raw data\n",
    "context_window = 3\n",
    "\n",
    "X, Y = [], []\n",
    "for word in words[:5]:\n",
    "    context = [0] * context_window\n",
    "    for char in word + '.':\n",
    "        itos_context= [itos[i] for i in context]\n",
    "        stoi_char = stoi[char]\n",
    "        X.append(context)\n",
    "        Y.append(stoi_char)\n",
    "        # print(f\"for context {''.join(itos_context)} ===> {char}\")\n",
    "        context = context[1:] + [stoi[char]]\n",
    "        # print(char)\n",
    "        \n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n",
    "\n",
    "print(f\"shape for input: {X.shape} ===> Targe shape {Y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## creating the embedding matrix. think of representing each letter with 2 values instead of 1 like one hot. here 2 is embedding size\n",
    "embedding_size = 2\n",
    "C = torch.randn((len(stoi), embedding_size))\n",
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiple the input with the embedding matrix. effectively we are seeing input integet representing char in each input and querying for its embedding value.\n",
    "# for 32 examples, with 3 chars/words each, and each char/words represented by 2 values, we get (32, 3, 2)\n",
    "\n",
    "C[X].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X]\n",
    "\n",
    "# we can stack each of the 3 char/words together. we can also flatten its embedding into a 1d vector. \n",
    "# so we are getting 3 1d vectors of length 2 and concating them into single vector giving us (32, 6)\n",
    "\n",
    "emb = emb.view(-1, context_window * embedding_size)\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually creating the weights and biases for the model [3 words each being represented by 2 values * 1 layer of 100 neurons * 1 output layer of 27 classes]\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "embedding_size = 2\n",
    "C = torch.randn((len(stoi), embedding_size))\n",
    "W1 = torch.randn((embedding_size * context_window, 100), generator=g)\n",
    "B1 = torch.randn((100), generator=g)\n",
    "W2 = torch.randn((100, len(stoi)), generator=g)\n",
    "B2 = torch.randn((len(stoi)), generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X]\n",
    "h = torch.tanh(emb.view(-1, context_window * embedding_size) @ W1 + B1)\n",
    "logits = h @ W2 + B2\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X]\n",
    "h = torch.tanh(emb.view(-1, context_window * embedding_size) @ W1 + B1)\n",
    "logits = h @ W2 + B2\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(-1, keepdim=True)\n",
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[torch.arange(len(Y)), Y].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs for 32 inputs at correct prediction \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.3125e-09, 5.3484e-14, 3.6140e-08, 3.9006e-08, 4.6471e-08, 8.7818e-14,\n",
       "        6.2721e-07, 3.0474e-09, 9.0487e-09, 1.3605e-07, 2.0612e-01, 1.2362e-10,\n",
       "        6.2226e-07, 6.2992e-09, 8.1582e-08, 8.0139e-10, 9.0715e-10, 2.8441e-11,\n",
       "        5.5209e-05, 1.4619e-12, 5.5277e-11, 8.2960e-06, 5.6776e-06, 3.0789e-06,\n",
       "        2.1748e-09, 1.3100e-10, 4.8137e-14, 6.3812e-10, 4.6483e-02, 8.0428e-03,\n",
       "        6.2098e-04, 1.7615e-07])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is indexing into the probability of each predicted for the correct class.\n",
    "# torch.range(1, len(Y)).long() this gives us a list from 1 to len(input) and Y gives us the correct class in form of integer for each input\n",
    "# using the combination of above we can index into what the probabilities are for the correct class for each input in our models output\n",
    "print(\"probs for 32 inputs at correct prediction \")\n",
    "probs[torch.arange(len(Y)), Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.5882)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss= -probs[torch.arange(len(Y)), Y].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zero_to_hero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
